<div align="center">
  <h1>DiTer++ Datasets</h1>
<p align="center"><img src=fig/IMG_0014.jpg/></p>
  <a href="https://arxiv.org/abs/2412.05839"><img src="https://img.shields.io/badge/arXiv-2412.05839-b31b1b.svg?style=flat-square" alt="Arxiv" /></a>
  <a href="https://sites.google.com/view/diter-plusplus"><img src="https://github.com/sparolab/Joint_ID/blob/main/fig/badges/badge-website.svg" alt="Project" /></a>
  <a href="https://youtu.be/RJ_netgAOT8"><img src="https://badges.aleen42.com/src/youtube.svg" alt="YouTube" /></a>
  <br />
  <br />
  
**(Under Review) [IEEE ICRA 25]** This repository is the official code for DiTer++: Diverse Terrain and Multi-modal Dataset for Multi-Robot Navigation in Multi-session Outdoor Environments.

  <a href="https://scholar.google.com/citations?user=2bvLmqQAAAAJ&hl=ko" target="_blank">Juwon Kim</a><sup></sup>,
  <a href="https://scholar.google.com/citations?user=t5UEbooAAAAJ&hl=ko" target="_blank">Hogyun Kim</a><sup></sup>,
  <a href="https://scholar.google.com/citations?user=ZAO6skQAAAAJ&hl=ko" target="_blank">Seokhwan Jeong</a><sup></sup>,
  <a href="https://scholar.google.com/citations?user=gGfBRawAAAAJ&hl=ko" target="_blank">Youngsik Shin</a><sup></sup>,
  <a href="https://scholar.google.com/citations?user=W5MOKWIAAAAJ&hl=ko" target="_blank">Younggun Cho</a><sup>â€ </sup>

**[Spatial AI and Robotics Lab (SPARO)](https://sites.google.com/view/sparo/%ED%99%88?authuser=0&pli=1)**
  
</div>

## News
* Accepted in ICRA24 / Workshop on Future of Construction
* Submitted to ICRA25


## Download
* The dataset is provided on-demand. Link containing all data in our paper will be uploaded soon. 

## Sensor Configuration
* We configure multiple legged robot with various sensors offered in multi-session datasets.
	<p align="center"><img src=fig/sensor_setup.png/></p>
### Calibration
* Sensor calibration parameters including intrinsic & extrinsic will be uploaded soon.

## Data & Topic
* Our data are stored in rosbag format
* Each agent has custom namespace of its own to be distinguishable
* Topic name for each sensor are listed in table below
	<p align="center"><img src=fig/topics.png /></p>	

## Cite DiTer++
<pre>
<code>
@article{kim2024diter,
  title={DiTer++: Diverse Terrain and Multi-modal Dataset for Multi-Robot Navigation in Multi-session Outdoor Environments},
  author={Kim, Juwon, Kim, Hogyun, Jeong, Seokhwan, Shin, Youngsik and  and Cho, Younggun}
}
</code>
</pre>  

## Distribution License
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a>

DiTer++ is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>. 

Please read the license and use our data set accordingly. Thank you very much for your interest!

## Contact
* **Juwon Kim (lambertkim317@gmail.com)**
* **Seokhwan Jeong (eric5709@inha.edu)**
* **Hogyun Kim (hg.kim@inha.edu)**


